# coding=utf-8
# Copyright 2022-present, the HuggingFace Inc. team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
WARNING: this file is automatically generated by `utils/check_threaded_hf_api.py`. Do not edit it manually.
You can check it is up-to-date by running `make quality` and update its content with `make style` if needed.

The content of this file is mostly based on HfApi implementation.
"""
from __future__ import annotations

from concurrent.futures import Future, ThreadPoolExecutor
from typing import Dict, Optional, Union

from .hf_api import *  # noqa: F403
from .hf_api import _HfApi


class _ThreadedHfApi(_HfApi):
    _thread_pool: Optional[ThreadPoolExecutor] = None

    @property
    def thread_pool(self) -> ThreadPoolExecutor:
        # Calls to the Hub can be run in the background. Tasks are queued to preserve order but do not block the main
        # thread. Can be useful to upload data during a training. ThreadPoolExecutor is initialized the first time it's
        # used. Non-blocking methods are suffixed by `_threaded`.
        if self._thread_pool is None:
            self._thread_pool = ThreadPoolExecutor(max_workers=1)
        return self._thread_pool

    def add_space_secret_threaded(
        self, repo_id: str, key: str, value: str, *, token: Optional[str] = None
    ) -> Future[None]:
        """
        Adds or updates a secret in a Space.

        This is a non-blocking method. Check out [`add_space_secret`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.add_space_secret, repo_id, key, value, token=token)

    def change_discussion_status_threaded(
        self,
        repo_id: str,
        discussion_num: int,
        new_status: Literal["open", "closed"],
        *,
        token: Optional[str] = None,
        comment: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[DiscussionStatusChange]:
        """
        Closes or re-opens a Discussion or Pull Request.

        This is a non-blocking method. Check out [`change_discussion_status`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.change_discussion_status,
            repo_id,
            discussion_num,
            new_status,
            token=token,
            comment=comment,
            repo_type=repo_type,
        )

    def comment_discussion_threaded(
        self,
        repo_id: str,
        discussion_num: int,
        comment: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[DiscussionComment]:
        """
        Creates a new comment on the given Discussion.

        This is a non-blocking method. Check out [`comment_discussion`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.comment_discussion, repo_id, discussion_num, comment, token=token, repo_type=repo_type
        )

    def create_branch_threaded(
        self,
        repo_id: str,
        *,
        branch: str,
        revision: Optional[str] = None,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
        exist_ok: bool = False,
    ) -> Future[None]:
        """
        Create a new branch for a repo on the Hub, starting from the specified revision (defaults to `main`).

        This is a non-blocking method. Check out [`create_branch`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.create_branch,
            repo_id,
            branch=branch,
            revision=revision,
            token=token,
            repo_type=repo_type,
            exist_ok=exist_ok,
        )

    def create_commit_threaded(
        self,
        repo_id: str,
        operations: Iterable[CommitOperation],
        *,
        commit_message: str,
        commit_description: Optional[str] = None,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
        revision: Optional[str] = None,
        create_pr: Optional[bool] = None,
        num_threads: int = 5,
        parent_commit: Optional[str] = None,
    ) -> Future[CommitInfo]:
        """
        Creates a commit in the given repo, deleting & uploading files as needed.

        This is a non-blocking method. Check out [`create_commit`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.create_commit,
            repo_id,
            operations,
            commit_message=commit_message,
            commit_description=commit_description,
            token=token,
            repo_type=repo_type,
            revision=revision,
            create_pr=create_pr,
            num_threads=num_threads,
            parent_commit=parent_commit,
        )

    def create_commits_on_pr_threaded(
        self,
        *,
        repo_id: str,
        addition_commits: List[List[CommitOperationAdd]],
        deletion_commits: List[List[CommitOperationDelete]],
        commit_message: str,
        commit_description: Optional[str] = None,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
        merge_pr: bool = True,
        num_threads: int = 5,  # TODO: use to multithread uploads
        verbose: bool = False,
    ) -> Future[str]:
        """
        Push changes to the Hub in multiple commits.

        This is a non-blocking method. Check out [`create_commits_on_pr`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.create_commits_on_pr,
            repo_id=repo_id,
            addition_commits=addition_commits,
            deletion_commits=deletion_commits,
            commit_message=commit_message,
            commit_description=commit_description,
            token=token,
            repo_type=repo_type,
            merge_pr=merge_pr,
            num_threads=num_threads,
            verbose=verbose,
        )

    def create_discussion_threaded(
        self,
        repo_id: str,
        title: str,
        *,
        token: Optional[str] = None,
        description: Optional[str] = None,
        repo_type: Optional[str] = None,
        pull_request: bool = False,
    ) -> Future[DiscussionWithDetails]:
        """
        Creates a Discussion or Pull Request.

        This is a non-blocking method. Check out [`create_discussion`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.create_discussion,
            repo_id,
            title,
            token=token,
            description=description,
            repo_type=repo_type,
            pull_request=pull_request,
        )

    def create_pull_request_threaded(
        self,
        repo_id: str,
        title: str,
        *,
        token: Optional[str] = None,
        description: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[DiscussionWithDetails]:
        """
        Creates a Pull Request . Pull Requests created programmatically will be in `"draft"` status.

        This is a non-blocking method. Check out [`create_pull_request`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.create_pull_request, repo_id, title, token=token, description=description, repo_type=repo_type
        )

    def create_repo_threaded(
        self,
        repo_id: str,
        *,
        token: Optional[str] = None,
        private: bool = False,
        repo_type: Optional[str] = None,
        exist_ok: bool = False,
        space_sdk: Optional[str] = None,
        space_hardware: Optional[str] = None,
    ) -> Future[RepoUrl]:
        """
        Create an empty repo on the HuggingFace Hub.

        This is a non-blocking method. Check out [`create_repo`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.create_repo,
            repo_id,
            token=token,
            private=private,
            repo_type=repo_type,
            exist_ok=exist_ok,
            space_sdk=space_sdk,
            space_hardware=space_hardware,
        )

    def create_tag_threaded(
        self,
        repo_id: str,
        *,
        tag: str,
        tag_message: Optional[str] = None,
        revision: Optional[str] = None,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
        exist_ok: bool = False,
    ) -> Future[None]:
        """
        Tag a given commit of a repo on the Hub.

        This is a non-blocking method. Check out [`create_tag`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.create_tag,
            repo_id,
            tag=tag,
            tag_message=tag_message,
            revision=revision,
            token=token,
            repo_type=repo_type,
            exist_ok=exist_ok,
        )

    def dataset_info_threaded(
        self,
        repo_id: str,
        *,
        revision: Optional[str] = None,
        timeout: Optional[float] = None,
        files_metadata: bool = False,
        token: Optional[Union[bool, str]] = None,
    ) -> Future[DatasetInfo]:
        """
        Get info on one specific dataset on huggingface.co.

        This is a non-blocking method. Check out [`dataset_info`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.dataset_info, repo_id, revision=revision, timeout=timeout, files_metadata=files_metadata, token=token
        )

    def delete_branch_threaded(
        self,
        repo_id: str,
        *,
        branch: str,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[None]:
        """
        Delete a branch from a repo on the Hub.

        This is a non-blocking method. Check out [`delete_branch`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.delete_branch, repo_id, branch=branch, token=token, repo_type=repo_type)

    def delete_file_threaded(
        self,
        path_in_repo: str,
        repo_id: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
        revision: Optional[str] = None,
        commit_message: Optional[str] = None,
        commit_description: Optional[str] = None,
        create_pr: Optional[bool] = None,
        parent_commit: Optional[str] = None,
    ) -> Future[CommitInfo]:
        """
        Deletes a file in the given repo.

        This is a non-blocking method. Check out [`delete_file`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.delete_file,
            path_in_repo,
            repo_id,
            token=token,
            repo_type=repo_type,
            revision=revision,
            commit_message=commit_message,
            commit_description=commit_description,
            create_pr=create_pr,
            parent_commit=parent_commit,
        )

    def delete_folder_threaded(
        self,
        path_in_repo: str,
        repo_id: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
        revision: Optional[str] = None,
        commit_message: Optional[str] = None,
        commit_description: Optional[str] = None,
        create_pr: Optional[bool] = None,
        parent_commit: Optional[str] = None,
    ) -> Future[CommitInfo]:
        """
        Deletes a folder in the given repo.

        This is a non-blocking method. Check out [`delete_folder`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.delete_folder,
            path_in_repo,
            repo_id,
            token=token,
            repo_type=repo_type,
            revision=revision,
            commit_message=commit_message,
            commit_description=commit_description,
            create_pr=create_pr,
            parent_commit=parent_commit,
        )

    def delete_repo_threaded(
        self,
        repo_id: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ):
        """
        Delete a repo from the HuggingFace Hub. CAUTION: this is irreversible.

        This is a non-blocking method. Check out [`delete_repo`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.delete_repo, repo_id, token=token, repo_type=repo_type)

    def delete_space_secret_threaded(self, repo_id: str, key: str, *, token: Optional[str] = None) -> Future[None]:
        """
        Deletes a secret from a Space.

        This is a non-blocking method. Check out [`delete_space_secret`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.delete_space_secret, repo_id, key, token=token)

    def delete_tag_threaded(
        self,
        repo_id: str,
        *,
        tag: str,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[None]:
        """
        Delete a tag from a repo on the Hub.

        This is a non-blocking method. Check out [`delete_tag`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.delete_tag, repo_id, tag=tag, token=token, repo_type=repo_type)

    def duplicate_space_threaded(
        self,
        from_id: str,
        to_id: Optional[str] = None,
        *,
        private: Optional[bool] = None,
        token: Optional[str] = None,
        exist_ok: bool = False,
    ) -> Future[RepoUrl]:
        """
        Duplicate a Space.

        This is a non-blocking method. Check out [`duplicate_space`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.duplicate_space, from_id, to_id, private=private, token=token, exist_ok=exist_ok
        )

    def edit_discussion_comment_threaded(
        self,
        repo_id: str,
        discussion_num: int,
        comment_id: str,
        new_content: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[DiscussionComment]:
        """
        Edits a comment on a Discussion / Pull Request.

        This is a non-blocking method. Check out [`edit_discussion_comment`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.edit_discussion_comment,
            repo_id,
            discussion_num,
            comment_id,
            new_content,
            token=token,
            repo_type=repo_type,
        )

    def get_dataset_tags_threaded(self) -> Future[DatasetTags]:
        """
        List all valid dataset tags as a nested namespace object.

        This is a non-blocking method. Check out [`get_dataset_tags`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.get_dataset_tags,
        )

    def get_discussion_details_threaded(
        self,
        repo_id: str,
        discussion_num: int,
        *,
        repo_type: Optional[str] = None,
        token: Optional[str] = None,
    ) -> Future[DiscussionWithDetails]:
        """
        Fetches a Discussion's / Pull Request 's details from the Hub.

        This is a non-blocking method. Check out [`get_discussion_details`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.get_discussion_details, repo_id, discussion_num, repo_type=repo_type, token=token
        )

    def get_full_repo_name_threaded(
        self,
        model_id: str,
        *,
        organization: Optional[str] = None,
        token: Optional[Union[bool, str]] = None,
    ):
        """
        Returns the repository name for a given model ID and optional

        This is a non-blocking method. Check out [`get_full_repo_name`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.get_full_repo_name, model_id, organization=organization, token=token)

    def get_model_tags_threaded(self) -> Future[ModelTags]:
        """
        List all valid model tags as a nested namespace object

        This is a non-blocking method. Check out [`get_model_tags`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.get_model_tags,
        )

    def get_repo_discussions_threaded(
        self,
        repo_id: str,
        *,
        repo_type: Optional[str] = None,
        token: Optional[str] = None,
    ) -> Future[Iterator[Discussion]]:
        """
        Fetches Discussions and Pull Requests for the given repo.

        This is a non-blocking method. Check out [`get_repo_discussions`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.get_repo_discussions, repo_id, repo_type=repo_type, token=token)

    def get_space_runtime_threaded(self, repo_id: str, *, token: Optional[str] = None) -> Future[SpaceRuntime]:
        """
        Gets runtime information about a Space.

        This is a non-blocking method. Check out [`get_space_runtime`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.get_space_runtime, repo_id, token=token)

    def hide_discussion_comment_threaded(
        self,
        repo_id: str,
        discussion_num: int,
        comment_id: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[DiscussionComment]:
        """
        Hides a comment on a Discussion / Pull Request.

        This is a non-blocking method. Check out [`hide_discussion_comment`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.hide_discussion_comment, repo_id, discussion_num, comment_id, token=token, repo_type=repo_type
        )

    def like_threaded(
        self,
        repo_id: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[None]:
        """
        Like a given repo on the Hub (e.g. set as favorite).

        This is a non-blocking method. Check out [`like`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.like, repo_id, token=token, repo_type=repo_type)

    def list_datasets_threaded(
        self,
        *,
        filter: Union[DatasetFilter, str, Iterable[str], None] = None,
        author: Optional[str] = None,
        search: Optional[str] = None,
        sort: Union[Literal["lastModified"], str, None] = None,
        direction: Optional[Literal[-1]] = None,
        limit: Optional[int] = None,
        cardData: Optional[bool] = None,  # deprecated
        full: Optional[bool] = None,
        token: Optional[str] = None,
    ) -> Future[List[DatasetInfo]]:
        """
        Get the list of all the datasets on huggingface.co

        This is a non-blocking method. Check out [`list_datasets`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.list_datasets,
            filter=filter,
            author=author,
            search=search,
            sort=sort,
            direction=direction,
            limit=limit,
            cardData=cardData,
            full=full,
            token=token,
        )

    def list_files_info_threaded(
        self,
        repo_id: str,
        paths: Union[List[str], str, None] = None,
        *,
        expand: bool = False,
        revision: Optional[str] = None,
        repo_type: Optional[str] = None,
        token: Optional[Union[bool, str]] = None,
    ) -> Future[Iterable[RepoFile]]:
        """
        List files on a repo and get information about them.

        This is a non-blocking method. Check out [`list_files_info`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.list_files_info, repo_id, paths, expand=expand, revision=revision, repo_type=repo_type, token=token
        )

    def list_liked_repos_threaded(
        self,
        user: Optional[str] = None,
        *,
        token: Optional[str] = None,
    ) -> Future[UserLikes]:
        """
        List all public repos liked by a user on huggingface.co.

        This is a non-blocking method. Check out [`list_liked_repos`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.list_liked_repos, user, token=token)

    def list_metrics_threaded(self) -> Future[List[MetricInfo]]:
        """
        Get the public list of all the metrics on huggingface.co

        This is a non-blocking method. Check out [`list_metrics`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.list_metrics,
        )

    def list_models_threaded(
        self,
        *,
        filter: Union[ModelFilter, str, Iterable[str], None] = None,
        author: Optional[str] = None,
        search: Optional[str] = None,
        emissions_thresholds: Optional[Tuple[float, float]] = None,
        sort: Union[Literal["lastModified"], str, None] = None,
        direction: Optional[Literal[-1]] = None,
        limit: Optional[int] = None,
        full: Optional[bool] = None,
        cardData: bool = False,
        fetch_config: bool = False,
        token: Optional[Union[bool, str]] = None,
    ) -> Future[List[ModelInfo]]:
        """
        Get the list of all the models on huggingface.co

        This is a non-blocking method. Check out [`list_models`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.list_models,
            filter=filter,
            author=author,
            search=search,
            emissions_thresholds=emissions_thresholds,
            sort=sort,
            direction=direction,
            limit=limit,
            full=full,
            cardData=cardData,
            fetch_config=fetch_config,
            token=token,
        )

    def list_repo_commits_threaded(
        self,
        repo_id: str,
        *,
        repo_type: Optional[str] = None,
        token: Optional[Union[bool, str]] = None,
        revision: Optional[str] = None,
        formatted: bool = False,
    ) -> Future[List[GitCommitInfo]]:
        """
        Get the list of commits of a given revision for a repo on the Hub.

        This is a non-blocking method. Check out [`list_repo_commits`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.list_repo_commits, repo_id, repo_type=repo_type, token=token, revision=revision, formatted=formatted
        )

    def list_repo_files_threaded(
        self,
        repo_id: str,
        *,
        revision: Optional[str] = None,
        repo_type: Optional[str] = None,
        timeout: Optional[float] = None,
        token: Optional[Union[bool, str]] = None,
    ) -> Future[List[str]]:
        """
        Get the list of files in a given repo.

        This is a non-blocking method. Check out [`list_repo_files`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.list_repo_files, repo_id, revision=revision, repo_type=repo_type, timeout=timeout, token=token
        )

    def list_repo_refs_threaded(
        self,
        repo_id: str,
        *,
        repo_type: Optional[str] = None,
        token: Optional[Union[bool, str]] = None,
    ) -> Future[GitRefs]:
        """
        Get the list of refs of a given repo (both tags and branches).

        This is a non-blocking method. Check out [`list_repo_refs`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.list_repo_refs, repo_id, repo_type=repo_type, token=token)

    def list_spaces_threaded(
        self,
        *,
        filter: Union[str, Iterable[str], None] = None,
        author: Optional[str] = None,
        search: Optional[str] = None,
        sort: Union[Literal["lastModified"], str, None] = None,
        direction: Optional[Literal[-1]] = None,
        limit: Optional[int] = None,
        datasets: Union[str, Iterable[str], None] = None,
        models: Union[str, Iterable[str], None] = None,
        linked: bool = False,
        full: Optional[bool] = None,
        token: Optional[str] = None,
    ) -> Future[List[SpaceInfo]]:
        """
        Get the public list of all Spaces on huggingface.co

        This is a non-blocking method. Check out [`list_spaces`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.list_spaces,
            filter=filter,
            author=author,
            search=search,
            sort=sort,
            direction=direction,
            limit=limit,
            datasets=datasets,
            models=models,
            linked=linked,
            full=full,
            token=token,
        )

    def merge_pull_request_threaded(
        self,
        repo_id: str,
        discussion_num: int,
        *,
        token: Optional[str] = None,
        comment: Optional[str] = None,
        repo_type: Optional[str] = None,
    ):
        """
        Merges a Pull Request.

        This is a non-blocking method. Check out [`merge_pull_request`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.merge_pull_request, repo_id, discussion_num, token=token, comment=comment, repo_type=repo_type
        )

    def model_info_threaded(
        self,
        repo_id: str,
        *,
        revision: Optional[str] = None,
        timeout: Optional[float] = None,
        securityStatus: Optional[bool] = None,
        files_metadata: bool = False,
        token: Optional[Union[bool, str]] = None,
    ) -> Future[ModelInfo]:
        """
        Get info on one specific model on huggingface.co

        This is a non-blocking method. Check out [`model_info`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.model_info,
            repo_id,
            revision=revision,
            timeout=timeout,
            securityStatus=securityStatus,
            files_metadata=files_metadata,
            token=token,
        )

    def move_repo_threaded(
        self,
        from_id: str,
        to_id: str,
        *,
        repo_type: Optional[str] = None,
        token: Optional[str] = None,
    ):
        """
        Moving a repository from namespace1/repo_name1 to namespace2/repo_name2

        This is a non-blocking method. Check out [`move_repo`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.move_repo, from_id, to_id, repo_type=repo_type, token=token)

    def pause_space_threaded(self, repo_id: str, *, token: Optional[str] = None) -> Future[SpaceRuntime]:
        """
        Pause your Space.

        This is a non-blocking method. Check out [`pause_space`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.pause_space, repo_id, token=token)

    def rename_discussion_threaded(
        self,
        repo_id: str,
        discussion_num: int,
        new_title: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[DiscussionTitleChange]:
        """
        Renames a Discussion.

        This is a non-blocking method. Check out [`rename_discussion`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.rename_discussion, repo_id, discussion_num, new_title, token=token, repo_type=repo_type
        )

    def repo_info_threaded(
        self,
        repo_id: str,
        *,
        revision: Optional[str] = None,
        repo_type: Optional[str] = None,
        timeout: Optional[float] = None,
        files_metadata: bool = False,
        token: Optional[Union[bool, str]] = None,
    ) -> Future[Union[ModelInfo, DatasetInfo, SpaceInfo]]:
        """
        Get the info object for a given repo of a given type.

        This is a non-blocking method. Check out [`repo_info`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.repo_info,
            repo_id,
            revision=revision,
            repo_type=repo_type,
            timeout=timeout,
            files_metadata=files_metadata,
            token=token,
        )

    def request_space_hardware_threaded(
        self,
        repo_id: str,
        hardware: SpaceHardware,
        *,
        token: Optional[str] = None,
        sleep_time: Optional[int] = None,
    ) -> Future[SpaceRuntime]:
        """
        Request new hardware for a Space.

        This is a non-blocking method. Check out [`request_space_hardware`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.request_space_hardware, repo_id, hardware, token=token, sleep_time=sleep_time
        )

    def restart_space_threaded(self, repo_id: str, *, token: Optional[str] = None) -> Future[SpaceRuntime]:
        """
        Restart your Space.

        This is a non-blocking method. Check out [`restart_space`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.restart_space, repo_id, token=token)

    def set_space_sleep_time_threaded(
        self, repo_id: str, sleep_time: int, *, token: Optional[str] = None
    ) -> Future[SpaceRuntime]:
        """
        Set a custom sleep time for a Space running on upgraded hardware..

        This is a non-blocking method. Check out [`set_space_sleep_time`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.set_space_sleep_time, repo_id, sleep_time, token=token)

    def space_info_threaded(
        self,
        repo_id: str,
        *,
        revision: Optional[str] = None,
        timeout: Optional[float] = None,
        files_metadata: bool = False,
        token: Optional[Union[bool, str]] = None,
    ) -> Future[SpaceInfo]:
        """
        Get info on one specific Space on huggingface.co.

        This is a non-blocking method. Check out [`space_info`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.space_info, repo_id, revision=revision, timeout=timeout, files_metadata=files_metadata, token=token
        )

    def unlike_threaded(
        self,
        repo_id: str,
        *,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
    ) -> Future[None]:
        """
        Unlike a given repo on the Hub (e.g. remove from favorite list).

        This is a non-blocking method. Check out [`unlike`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.unlike, repo_id, token=token, repo_type=repo_type)

    def update_repo_visibility_threaded(
        self,
        repo_id: str,
        private: bool = False,
        *,
        token: Optional[str] = None,
        organization: Optional[str] = None,
        repo_type: Optional[str] = None,
        name: Optional[str] = None,
    ) -> Future[Dict[str, bool]]:
        """
        Update the visibility setting of a repository.

        This is a non-blocking method. Check out [`update_repo_visibility`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.update_repo_visibility,
            repo_id,
            private,
            token=token,
            organization=organization,
            repo_type=repo_type,
            name=name,
        )

    def upload_file_threaded(
        self,
        *,
        path_or_fileobj: Union[str, Path, bytes, BinaryIO],
        path_in_repo: str,
        repo_id: str,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
        revision: Optional[str] = None,
        commit_message: Optional[str] = None,
        commit_description: Optional[str] = None,
        create_pr: Optional[bool] = None,
        parent_commit: Optional[str] = None,
    ) -> Future[str]:
        """
        Upload a local file (up to 50 GB) to the given repo. The upload is done

        This is a non-blocking method. Check out [`upload_file`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.upload_file,
            path_or_fileobj=path_or_fileobj,
            path_in_repo=path_in_repo,
            repo_id=repo_id,
            token=token,
            repo_type=repo_type,
            revision=revision,
            commit_message=commit_message,
            commit_description=commit_description,
            create_pr=create_pr,
            parent_commit=parent_commit,
        )

    def upload_folder_threaded(
        self,
        *,
        repo_id: str,
        folder_path: Union[str, Path],
        path_in_repo: Optional[str] = None,
        commit_message: Optional[str] = None,
        commit_description: Optional[str] = None,
        token: Optional[str] = None,
        repo_type: Optional[str] = None,
        revision: Optional[str] = None,
        create_pr: Optional[bool] = None,
        parent_commit: Optional[str] = None,
        allow_patterns: Optional[Union[List[str], str]] = None,
        ignore_patterns: Optional[Union[List[str], str]] = None,
        delete_patterns: Optional[Union[List[str], str]] = None,
        multi_commits: bool = False,
        multi_commits_verbose: bool = False,
    ):
        """
        Upload a local folder to the given repo. The upload is done through a HTTP requests, and doesn't require git or

        This is a non-blocking method. Check out [`upload_folder`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(
            self.upload_folder,
            repo_id=repo_id,
            folder_path=folder_path,
            path_in_repo=path_in_repo,
            commit_message=commit_message,
            commit_description=commit_description,
            token=token,
            repo_type=repo_type,
            revision=revision,
            create_pr=create_pr,
            parent_commit=parent_commit,
            allow_patterns=allow_patterns,
            ignore_patterns=ignore_patterns,
            delete_patterns=delete_patterns,
            multi_commits=multi_commits,
            multi_commits_verbose=multi_commits_verbose,
        )

    def whoami_threaded(self, token: Optional[str] = None) -> Future[Dict]:
        """
        Call HF API to know "whoami".

        This is a non-blocking method. Check out [`whoami`] documentation to learn how to use it. The threaded version
        starts a background job in a separate thread and returns a Future object. The goal of background jobs is to
        avoid blocking the main thread for example in a training. You should not expect a gain in performances by
        parallelizing tasks with multiple threads as we favored a solution where jobs are run sequentially to preserve
        order. If you need more flexibility, you can have a look to the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
        documentation.
        """
        return self.thread_pool.submit(self.whoami, token)
